{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVHIsu1ze14J"
      },
      "source": [
        "# Let's Install the Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--VgC7Mfe1eG",
        "outputId": "ca4fb4f1-81d9-4019-a550-41f5b4153f4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 447 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 47.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 41.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 44.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 26.7 MB 49.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 159 kB 50.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 7.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 2.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 381 kB 47.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 36.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 40 kB 4.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 16.8 MB 23.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 35.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 256 kB 47.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 47.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 49.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 35.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 1.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.7 MB 32.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 37.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 47.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 210 kB 48.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 739 kB/s \n",
            "\u001b[K     |████████████████████████████████| 146 kB 45.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 46.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 6.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 35.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 880 kB 45.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.1 MB/s \n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'grpcio' candidate (version 1.45.0 at https://files.pythonhosted.org/packages/b8/ab/c7abc950e222c4cab5f7fd92107f3b09553061f673f1a670e6569105f584/grpcio-1.45.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=cc135b77f384a84bac67a37947886986be136356446338d64160a30c85f20c6d (from https://pypi.org/simple/grpcio/) (requires-python:>=3.6))\n",
            "Reason for being yanked: Segfaults\u001b[0m\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'grpcio-tools' candidate (version 1.45.0 at https://files.pythonhosted.org/packages/be/e1/70dac693e6df7e4f3108dfd3a82f86f0cd3742d9afe98bb2fe4333a3edd7/grpcio_tools-1.45.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=7db11a65e07410db1c31cbeb9afe344a6bd88a63dcd819557707ca7318478727 (from https://pypi.org/simple/grpcio-tools/) (requires-python:>=3.6))\n",
            "Reason for being yanked: grpcio 1.45.0 was yanked\u001b[0m\n",
            "\u001b[?25h  Building wheel for validate-email (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for polling (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "nbclient 0.6.2 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
            "ipython 5.5.0 requires prompt-toolkit<2.0.0,>=1.0.4, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install layer --upgrade -q\n",
        "!pip install sentencepiece -q\n",
        "!pip install transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxNNjwinfQFB"
      },
      "outputs": [],
      "source": [
        "from layer.decorators import dataset, model,resources, pip_requirements, fabric\n",
        "from layer import Model\n",
        "import layer\n",
        "import torch\n",
        "import random\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3TNqIaViq6w"
      },
      "source": [
        "## Getting started with Layer:\n",
        "- Login to Layer Console\n",
        "- Initialize the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0pK0QY9fTKV",
        "outputId": "165da890-c341-436d-bd32-0ef413eb4826"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please open the following link in your web browser. Once logged in, copy the code and paste it here.\n",
            "https://app.layer.ai/oauth/authorize?response_type=code&code_challenge=cHP7ajj_JrNpJPp__t2q3e0ddu1BW6f4PBx46HG9qss&code_challenge_method=S256&client_id=0STDdcnpK48P8A429EAAn93WNuLmViLR&redirect_uri=https://app.layer.ai/oauth/code&scope=offline_access&audience=https://app.layer.ai\n",
            "Code: YEfx0q49OMLrEVwNcCgIvPnboe5l8WukkePNgNbXoacqF\n",
            "Successfully logged into https://app.layer.ai\n"
          ]
        }
      ],
      "source": [
        "# Login to Layer:\n",
        "layer.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JObyccnfeZO",
        "outputId": "405027b1-ddcd-4c21-8d90-b1d07c70080b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Project(name='GPT2_text_summarization', raw_datasets=[], derived_datasets=[], models=[], path=PosixPath('.'), project_files_hash='', readme='', account=Account(id=UUID('c9442765-3fe4-4729-a7e4-d3fc9b07726b'), name='aymane_hachcham'), _id=UUID('f29c025a-0d92-4913-94ff-035d4de50df7'), functions=[])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Initialize the project:\n",
        "layer.init('GPT2_text_summarization')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXg4akFYjWMo"
      },
      "source": [
        "## Process and Load the Dataset to Layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmBoRT5NEsxG",
        "outputId": "a9d5e98c-1a9a-4962-98e9-7310b878ee95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cexb-rRzjGSn"
      },
      "outputs": [],
      "source": [
        "# Load the dataset:\n",
        "data_path = '/content/drive/MyDrive/GPT2/Dataset/Reviews.csv'\n",
        "import pandas as pd\n",
        "\n",
        "reviews = pd.read_csv(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYapNeyKjpmE",
        "outputId": "e9ff9066-141e-4c38-c644-526584825507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 568454 entries, 0 to 568453\n",
            "Data columns (total 10 columns):\n",
            " #   Column                  Non-Null Count   Dtype \n",
            "---  ------                  --------------   ----- \n",
            " 0   Id                      568454 non-null  int64 \n",
            " 1   ProductId               568454 non-null  object\n",
            " 2   UserId                  568454 non-null  object\n",
            " 3   ProfileName             568438 non-null  object\n",
            " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
            " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
            " 6   Score                   568454 non-null  int64 \n",
            " 7   Time                    568454 non-null  int64 \n",
            " 8   Summary                 568427 non-null  object\n",
            " 9   Text                    568454 non-null  object\n",
            "dtypes: int64(5), object(5)\n",
            "memory usage: 43.4+ MB\n"
          ]
        }
      ],
      "source": [
        "reviews.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "Tg-V9jiWj5eQ",
        "outputId": "dd1a71b7-ef20-4b29-eee4-d8427fd4087e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id   ProductId          UserId                      ProfileName  \\\n",
              "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
              "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
              "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
              "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
              "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
              "\n",
              "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
              "0                     1                       1      5  1303862400   \n",
              "1                     0                       0      1  1346976000   \n",
              "2                     1                       1      4  1219017600   \n",
              "3                     3                       3      2  1307923200   \n",
              "4                     0                       0      5  1350777600   \n",
              "\n",
              "                 Summary                                               Text  \n",
              "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
              "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
              "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
              "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
              "4            Great taffy  Great taffy at a great price.  There was a wid...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a2ab65b-c065-482a-9329-0ce3c7de80cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a2ab65b-c065-482a-9329-0ce3c7de80cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a2ab65b-c065-482a-9329-0ce3c7de80cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a2ab65b-c065-482a-9329-0ce3c7de80cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "reviews.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing and Cleaning"
      ],
      "metadata": {
        "id": "g2QuK11-3zAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for null values:\n",
        "print(reviews.isna().sum())\n",
        "\n",
        "# Remove null values:\n",
        "reviews.dropna(inplace=True)\n",
        "\n",
        "# Combining the two columns review and summary:\n",
        "reviews['training'] = reviews['Text']  + 'TL;DR' + reviews['Summary']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziEy4_sk3x-P",
        "outputId": "64b32cf5-d1d7-4349-f35e-7aa20f76303f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Id                         0\n",
            "ProductId                  0\n",
            "UserId                     0\n",
            "ProfileName               16\n",
            "HelpfulnessNumerator       0\n",
            "HelpfulnessDenominator     0\n",
            "Score                      0\n",
            "Time                       0\n",
            "Summary                   27\n",
            "Text                       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviews[:1500].info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3204Ryx4GfR",
        "outputId": "cea76371-e125-42b8-f5b0-c574070f9240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1500 entries, 0 to 1499\n",
            "Data columns (total 11 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   Id                      1500 non-null   int64 \n",
            " 1   ProductId               1500 non-null   object\n",
            " 2   UserId                  1500 non-null   object\n",
            " 3   ProfileName             1500 non-null   object\n",
            " 4   HelpfulnessNumerator    1500 non-null   int64 \n",
            " 5   HelpfulnessDenominator  1500 non-null   int64 \n",
            " 6   Score                   1500 non-null   int64 \n",
            " 7   Time                    1500 non-null   int64 \n",
            " 8   Summary                 1500 non-null   object\n",
            " 9   Text                    1500 non-null   object\n",
            " 10  training                1500 non-null   object\n",
            "dtypes: int64(5), object(6)\n",
            "memory usage: 140.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We take 5000 rows from the whole data. So can avoid GPU out of memory:\n",
        "reviews = reviews[['Summary','Text','training']][:5000]"
      ],
      "metadata": {
        "id": "oXGideUQ4fUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNAF0Jp7j6pB"
      },
      "outputs": [],
      "source": [
        "# Save the dataset to Layer:\n",
        "@dataset('amazon_reviews')\n",
        "@resources(data_path)\n",
        "def read_reviews():\n",
        "    df = pd.read_csv(data_path) \n",
        "    # Remove null values:\n",
        "    df.dropna(inplace=True)  \n",
        "    # Combining the two columns review and summary:\n",
        "    df['training'] = df['Text'] + 'TL;DR' + df['Summary'] \n",
        "    df = df[['Summary','Text','training']][:5000]\n",
        "    return df\n",
        "\n",
        "read_reviews()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DJiT3EUoFTY",
        "outputId": "e85c32f4-4171-441a-e6de-17a5f0700b24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78.1608"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Take the average length of the reviews:\n",
        "sum_all_tokens = sum([len(review.split()) for review in reviews['training']])\n",
        "avg_length = sum_all_tokens / len(reviews['training'])\n",
        "avg_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8tAEEuPpYdZ"
      },
      "source": [
        "Since the average instance length in words is 80, we can assume that a max length of 150 will cover most of the instances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzPSIGo2oXzd"
      },
      "outputs": [],
      "source": [
        "max_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviews['training']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkrm41AvlUJe",
        "outputId": "7c3e0a51-3535-4136-f057-b726ce62f87d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       I have bought several of the Vitality canned d...\n",
              "1       Product arrived labeled as Jumbo Salted Peanut...\n",
              "2       This is a confection that has been around a fe...\n",
              "3       If you are looking for the secret ingredient i...\n",
              "4       Great taffy at a great price.  There was a wid...\n",
              "                              ...                        \n",
              "4995    I really wanted to like these.<br /><br />Firs...\n",
              "4996    I was not impressed with these cookies when I ...\n",
              "4997    The cookies came sealed and seem to be high qu...\n",
              "4998    These taste very good, but aren't like the BES...\n",
              "4999    I love these cookies. I am on the paleo diet r...\n",
              "Name: training, Length: 5000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@model(\"gpt2-tokenizer\")\n",
        "@fabric(\"f-medium\")\n",
        "def build_tokenizer():\n",
        "    from transformers import AutoTokenizer\n",
        "    # Load tokenizer from Hugging face\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "    return tokenizer\n",
        "  \n",
        "layer.run([build_tokenizer])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68,
          "referenced_widgets": [
            "0051b49a50c245b7bb42bd239a3f0c77",
            "dc92ece2211c40c8a7b10b9472b306b2"
          ]
        },
        "id": "rinybKnGJLpY",
        "outputId": "904e785f-a82a-4fd1-de7b-15788a9f0c2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[32m⠋\u001b[0m  gpt2-tokenizer       \u001b[38;2;0;0;0m━━━━━━━━━\u001b[0m\u001b[38;2;0;0;0m╸\u001b[0m TRAINING \u001b[39m[\u001b[0m\u001b[38;2;155;155;159m0:00:13\u001b[0m\u001b[39m]\u001b[0m                                   \n",
              "   \u001b[4;38;2;161;161;169m↳ \u001b[0m\u001b]8;id=737965;https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2-tokenizer\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2-tokenizer\u001b[0m\u001b]8;;\u001b\\ \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠋</span>  gpt2-tokenizer       <span style=\"color: #000000; text-decoration-color: #000000\">━━━━━━━━━╸</span> TRAINING <span style=\"color: #000000; text-decoration-color: #000000\">[</span><span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">0:00:13</span><span style=\"color: #000000; text-decoration-color: #000000\">]</span>                                   \n",
              "   <span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">↳ </span><a href=\"https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2-tokenizer\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2-tokenizer</span></a> \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Run(project_name='GPT2_text_summarization')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIa0VkL1p0Fq"
      },
      "source": [
        "## Load the Model and the Tokenizer from Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMe1Xk1DuK0o"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        " \n",
        "class GPT2ReviewDataset(Dataset):  \n",
        "    def __init__(self, tokenizer, reviews, max_len):\n",
        "        self.max_len = max_len\n",
        "        self.tokenizer = tokenizer\n",
        "        self.eos = self.tokenizer.eos_token\n",
        "        self.eos_id = self.tokenizer.eos_token_id\n",
        "        self.reviews = reviews\n",
        "        self.result = []\n",
        "\n",
        "        for review in self.reviews:\n",
        "            # Encode the text using tokenizer.encode(). We add EOS at the end\n",
        "            tokenized = self.tokenizer.encode(review + self.eos)\n",
        "            \n",
        "            # Padding/truncating the encoded sequence to max_len \n",
        "            padded = self.pad_truncate(tokenized)            \n",
        "\n",
        "            # Creating a tensor and adding to the result\n",
        "            self.result.append(torch.tensor(padded))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.result)\n",
        "\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.result[item]\n",
        "\n",
        "    def pad_truncate(self, name):\n",
        "        extra_length = 4\n",
        "        name_length = len(name) - extra_length\n",
        "        if name_length < self.max_len:\n",
        "            difference = self.max_len - name_length\n",
        "            result = name + [self.eos_id] * difference\n",
        "        elif name_length > self.max_len:\n",
        "            result = name[:self.max_len + 3]+[self.eos_id] \n",
        "        else:\n",
        "            result = name\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = layer.get_model('aymane_hachcham/GPT2_text_summarization/models/tokenizer:2.2').get_train()"
      ],
      "metadata": {
        "id": "Xjkq5v_iJw74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetching the data from Layer to format the Dataset object:\n",
        "reviews = layer.get_dataset('layer/california_housing/datasets/train:1.1').to_pandas()"
      ],
      "metadata": {
        "id": "pCY1wnsT8HUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cX0cW6MtGcO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c44d40c-a9d0-4ec3-d925-894441fbdd1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1430 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "reviews_dataset = GPT2ReviewDataset(tokenizer, reviews['trainig'], max_length)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of the review_dataset:\n",
        "for item in reviews_dataset: \n",
        "  print(tokenizer.decode(item)), print(item)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cacMcAsxKB-y",
        "outputId": "bd1436c6-5367-4e75-cd3f-9ce51cb358e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.TL;DRGood Quality Dog Food<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
            "tensor([   40,   423,  5839,  1811,   286,   262, 28476,   414, 32530,  3290,\n",
            "         2057,  3186,   290,   423,  1043,   606,   477,   284,   307,   286,\n",
            "          922,  3081,    13,   383,  1720,  3073,   517,   588,   257, 20798,\n",
            "          621,   257, 13686,  6174,   290,   340, 25760,  1365,    13,  2011,\n",
            "        45246,   318,   957, 17479,   290,   673,  5763,   689,   428,  1720,\n",
            "         1365,   621,   220,   749,    13, 14990,    26,  7707, 10248, 14156,\n",
            "         8532,  7318, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKofMZWBG1a0"
      },
      "outputs": [],
      "source": [
        "dataloader = DataLoader(reviews_dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for s, n in enumerate(dataloader):\n",
        "  print(s, n)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84jBBKY_KrXR",
        "outputId": "773587fb-1b2c-4cea-a3d6-cd7233e69c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 tensor([[49123, 17166,  9155,  ..., 50256, 50256, 50256],\n",
            "        [ 3666,   807, 27406,  ..., 50256, 50256, 50256],\n",
            "        [   40,   373, 12451,  ..., 50256, 50256, 50256],\n",
            "        ...,\n",
            "        [44614, 12882,  8887,  ...,  2048,   355, 50256],\n",
            "        [ 4863,   718,  1227,  ..., 11676,    11, 50256],\n",
            "        [   40,   423, 15203,  ..., 50256, 50256, 50256]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, dl, epochs):    \n",
        "    for epoch in range(epochs):\n",
        "        for idx, batch in enumerate(dl):\n",
        "             with torch.set_grad_enabled(True):\n",
        "                optimizer.zero_grad()\n",
        "                batch = batch.to('cuda')\n",
        "                output = model(batch, labels=batch)\n",
        "                loss = output[0]\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                if idx % 50 == 0:\n",
        "                    print(\"loss: %f, %d\"%(loss, idx))"
      ],
      "metadata": {
        "id": "cmGkHBAYLjIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@model(\"gpt2_text_summarization\", dependencies=[Model(\"gpt2-tokenizer\")])\n",
        "@fabric(\"f-gpu-small\")\n",
        "@pip_requirements(packages=[\"torch\",\"transformers\",\"sentencepiece\"])\n",
        "def build_model():\n",
        "    from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "    from torch import cuda\n",
        "    import torch\n",
        "    from torch.utils.data import Dataset, DataLoader\n",
        "    from transformers import AutoModelWithLMHead\n",
        "    \n",
        "    parameters={\n",
        "        \"BATCH_SIZE\":32,          \n",
        "        \"EPOCHS\":10,              \n",
        "        \"LEARNING_RATE\":3e-4,          \n",
        "        \"MAX_TARGET_TEXT_LENGTH\":max_length\n",
        "    }\n",
        "\n",
        "    # Log parameters to Layer\n",
        "    layer.log(parameters)\n",
        "\n",
        "    # Get the tokenizer:\n",
        "    tokenizer = layer.get_model('aymane_hachcham/GPT2_text_summarization/models/tokenizer:2.2').get_train()\n",
        "  \n",
        "    # Load pretrained model from Hugging face\n",
        "    model = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
        "    device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(params = model.parameters(), lr=parameters['LEARNING_RATE'])\n",
        "\n",
        "    train(model, optimizer, dataloader, epochs=parameters['EPOCHS'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "l3Gm1xQ5InLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer.run([build_model], debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189,
          "referenced_widgets": [
            "4b1f08cded15460da199f0989f86d461",
            "0c7e05ebf7a148fc8d40799d27eff63f"
          ]
        },
        "id": "LnwhtUgb92mK",
        "outputId": "f77d4142-ad3b-41fb-88f6-ce89d2a52a5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "✅  gpt2_text_summariza… \u001b[38;2;21;127;61m━━━━━━━━━━\u001b[0m \u001b[38;2;21;127;61mDONE\u001b[0m \u001b[39m[\u001b[0m\u001b[38;2;155;155;159m0:44:23\u001b[0m\u001b[39m]\u001b[0m                                           \n",
              "    \u001b[4;38;2;161;161;169m↳ \u001b[0m\u001b]8;id=108052;https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summarization?v=3.2\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summariz\u001b[0m\u001b]8;;\u001b\\ \n",
              "    \u001b]8;id=108052;https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summarization?v=3.2\u001b\\\u001b[4;38;2;161;161;169mation?v=3.2\u001b[0m\u001b]8;;\u001b\\                                                                              \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅  gpt2_text_summariza… <span style=\"color: #157f3d; text-decoration-color: #157f3d\">━━━━━━━━━━</span> <span style=\"color: #157f3d; text-decoration-color: #157f3d\">DONE</span> <span style=\"color: #000000; text-decoration-color: #000000\">[</span><span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">0:44:23</span><span style=\"color: #000000; text-decoration-color: #000000\">]</span>                                           \n",
              "    <span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">↳ </span><a href=\"https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summarization?v=3.2\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summariz</span></a> \n",
              "    <a href=\"https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summarization?v=3.2\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">ation?v=3.2</span></a>                                                                              \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "✅  gpt2_text_summariza… \u001b[38;2;21;127;61m━━━━━━━━━━\u001b[0m \u001b[38;2;21;127;61mDONE\u001b[0m \u001b[39m[\u001b[0m\u001b[38;2;155;155;159m0:44:23\u001b[0m\u001b[39m]\u001b[0m                                           \n",
              "    \u001b[4;38;2;161;161;169m↳ \u001b[0m\u001b]8;id=238998;https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summarization?v=3.2\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summariz\u001b[0m\u001b]8;;\u001b\\ \n",
              "    \u001b]8;id=238998;https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summarization?v=3.2\u001b\\\u001b[4;38;2;161;161;169mation?v=3.2\u001b[0m\u001b]8;;\u001b\\                                                                              \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅  gpt2_text_summariza… <span style=\"color: #157f3d; text-decoration-color: #157f3d\">━━━━━━━━━━</span> <span style=\"color: #157f3d; text-decoration-color: #157f3d\">DONE</span> <span style=\"color: #000000; text-decoration-color: #000000\">[</span><span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">0:44:23</span><span style=\"color: #000000; text-decoration-color: #000000\">]</span>                                           \n",
              "    <span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">↳ </span><a href=\"https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summarization?v=3.2\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summariz</span></a> \n",
              "    <a href=\"https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summarization?v=3.2\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">ation?v=3.2</span></a>                                                                              \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "✅  gpt2_text_summariza… \u001b[38;2;21;127;61m━━━━━━━━━━\u001b[0m \u001b[38;2;21;127;61mDONE\u001b[0m \u001b[39m[\u001b[0m\u001b[38;2;155;155;159m0:44:23\u001b[0m\u001b[39m]\u001b[0m                                           \n",
              "    \u001b[4;38;2;161;161;169m↳ \u001b[0m\u001b]8;id=638600;https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summarization?v=3.2\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summariz\u001b[0m\u001b]8;;\u001b\\ \n",
              "    \u001b]8;id=638600;https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summarization?v=3.2\u001b\\\u001b[4;38;2;161;161;169mation?v=3.2\u001b[0m\u001b]8;;\u001b\\                                                                              \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅  gpt2_text_summariza… <span style=\"color: #157f3d; text-decoration-color: #157f3d\">━━━━━━━━━━</span> <span style=\"color: #157f3d; text-decoration-color: #157f3d\">DONE</span> <span style=\"color: #000000; text-decoration-color: #000000\">[</span><span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">0:44:23</span><span style=\"color: #000000; text-decoration-color: #000000\">]</span>                                           \n",
              "    <span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">↳ </span><a href=\"https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summarization?v=3.2\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summariz</span></a> \n",
              "    <a href=\"https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summarization?v=3.2\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">ation?v=3.2</span></a>                                                                              \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Run(project_name='GPT2_text_summarization')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yX8TwnlkIyuJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def topk(probs, n=9):\n",
        "    # The scores are initially softmaxed to convert to probabilities\n",
        "    probs = torch.softmax(probs, dim= -1)\n",
        "    \n",
        "    # PyTorch has its own topk method, which we use here\n",
        "    tokensProb, topIx = torch.topk(probs, k=n)\n",
        "    \n",
        "    # The new selection pool (9 choices) is normalized\n",
        "    tokensProb = tokensProb / torch.sum(tokensProb)\n",
        "\n",
        "    # Send to CPU for numpy handling\n",
        "    tokensProb = tokensProb.cpu().detach().numpy()\n",
        "\n",
        "    # Make a random choice from the pool based on the new prob distribution\n",
        "    choice = np.random.choice(n, 1, p = tokensProb)\n",
        "    tokenId = topIx[choice][0]\n",
        "\n",
        "    return int(tokenId)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcE0a2i2JshT"
      },
      "outputs": [],
      "source": [
        "def model_infer(model, tokenizer, review, max_length=15):\n",
        "    # Preprocess the init token (task designator)\n",
        "    review_encoded = tokenizer.encode(review)\n",
        "    result = review_encoded\n",
        "    initial_input = torch.tensor(review_encoded).unsqueeze(0).to('cpu')\n",
        "\n",
        "    with torch.set_grad_enabled(False):\n",
        "        # Feed the init token to the model\n",
        "        output = model(initial_input)\n",
        "\n",
        "        # Flatten the logits at the final time step\n",
        "        logits = output.logits\n",
        "\n",
        "        # Make a top-k choice and append to the result\n",
        "        result.append(topk(logits))\n",
        "\n",
        "        # For max_length times:\n",
        "        for _ in range(max_length):\n",
        "            # Feed the current sequence to the model and make a choice\n",
        "            input = torch.tensor(result).unsqueeze(0).to('cpu')\n",
        "            output = model(input)\n",
        "            logits = output.logits\n",
        "            res_id = topk(logits)\n",
        "\n",
        "            # If the chosen token is EOS, return the result\n",
        "            if res_id == tokenizer.eos_token_id:\n",
        "                return tokenizer.decode(result)\n",
        "            else: # Append to the sequence \n",
        "                result.append(res_id)\n",
        "\n",
        "    # IF no EOS is generated, return after the max_len\n",
        "    return tokenizer.decode(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aT67LC2zJ1gB"
      },
      "outputs": [],
      "source": [
        "samples = [review.split('TL;DR')[0] for review in list(reviews['training'].sample(n=3, random_state=1)['training'])]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gtp2_model = layer.get_model('aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summarization:3.1').get_train()"
      ],
      "metadata": {
        "id": "AUlyWEEJH46D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Then you can output the summary prediction from the samples using model_infer.\n",
        "\n",
        "for review in samples:\n",
        "    summaries = set()\n",
        "    print(review)\n",
        "    while len(summaries) < 3:\n",
        "        summary = model_infer(model, tokenizer, review + \" TL;DR \").split(\" TL;DR \")[1].strip()\n",
        "        if summary not in summaries:\n",
        "            summaries.add(summary)\n",
        "    print(\"Summaries: \"+ str(summaries) +\"\\n\")"
      ],
      "metadata": {
        "id": "m9gmDWechciY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "GPT2 for text sumarization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0051b49a50c245b7bb42bd239a3f0c77": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_dc92ece2211c40c8a7b10b9472b306b2",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "✅  gpt2-tokenizer       \u001b[38;2;21;127;61m━━━━━━━━━━\u001b[0m \u001b[38;2;21;127;61mDONE\u001b[0m \u001b[39m[\u001b[0m\u001b[38;2;155;155;159m0:00:15\u001b[0m\u001b[39m]\u001b[0m                                           \n    \u001b[4;38;2;161;161;169m↳ \u001b[0m                                                                                       \n    \u001b]8;id=669924;https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2-tokenizer?v=1.1\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2-tokenizer?v=1.1\u001b[0m\u001b]8;;\u001b\\ \n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅  gpt2-tokenizer       <span style=\"color: #157f3d; text-decoration-color: #157f3d\">━━━━━━━━━━</span> <span style=\"color: #157f3d; text-decoration-color: #157f3d\">DONE</span> <span style=\"color: #000000; text-decoration-color: #000000\">[</span><span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">0:00:15</span><span style=\"color: #000000; text-decoration-color: #000000\">]</span>                                           \n    <span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">↳ </span>                                                                                       \n    <a href=\"https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2-tokenizer?v=1.1\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2-tokenizer?v=1.1</span></a> \n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "dc92ece2211c40c8a7b10b9472b306b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b1f08cded15460da199f0989f86d461": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_0c7e05ebf7a148fc8d40799d27eff63f",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "✅  gpt2_text_summariza… \u001b[38;2;21;127;61m━━━━━━━━━━\u001b[0m \u001b[38;2;21;127;61mDONE\u001b[0m \u001b[39m[\u001b[0m\u001b[38;2;155;155;159m0:44:23\u001b[0m\u001b[39m]\u001b[0m                                           \n    \u001b[4;38;2;161;161;169m↳ \u001b[0m\u001b]8;id=104637;https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summarization?v=3.2\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summariz\u001b[0m\u001b]8;;\u001b\\ \n    \u001b]8;id=104637;https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summarization?v=3.2\u001b\\\u001b[4;38;2;161;161;169mation?v=3.2\u001b[0m\u001b]8;;\u001b\\                                                                              \n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅  gpt2_text_summariza… <span style=\"color: #157f3d; text-decoration-color: #157f3d\">━━━━━━━━━━</span> <span style=\"color: #157f3d; text-decoration-color: #157f3d\">DONE</span> <span style=\"color: #000000; text-decoration-color: #000000\">[</span><span style=\"color: #9b9b9f; text-decoration-color: #9b9b9f\">0:44:23</span><span style=\"color: #000000; text-decoration-color: #000000\">]</span>                                           \n    <span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">↳ </span><a href=\"https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summarization?v=3.2\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summariz</span></a> \n    <a href=\"https://app.layer.ai/aymane_hachcham/GPT2_text_summarization/models/gpt2_text_summarization?v=3.2\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">ation?v=3.2</span></a>                                                                              \n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "0c7e05ebf7a148fc8d40799d27eff63f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}